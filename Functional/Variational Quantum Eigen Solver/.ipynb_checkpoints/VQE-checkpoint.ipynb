{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f6b534e-c6eb-4e77-9fe2-120b8e73f016",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Variational Quantum Eigensolver Benchmark Program - Qiskit\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from qiskit import QuantumCircuit, QuantumRegister\n",
    "from qiskit.opflow import PauliTrotterEvolution, Suzuki\n",
    "from qiskit.opflow.primitive_ops import PauliSumOp\n",
    "from qiskit import *\n",
    "\n",
    "# Noise parameters\n",
    "options = { } #if Noise is None\n",
    "\n",
    "options_noisy = { #if Noise is not None\n",
    "    'plot': False,\n",
    "    \"thermal_factor\": 1.0,\n",
    "    'show_partition': False,\n",
    "    \"decoherence_factor\": 0.9,\n",
    "    \"depolarization_factor\": 0.9,\n",
    "    \"bell_depolarization_factor\": 0.9,\n",
    "    \"decay_factor\": 0.9,\n",
    "    \"rotation_error\": {'rx':[1.0, 0.0], 'ry':[1.0, 0.0], 'rz':[1.0, 0.0]},\n",
    "    \"tsp_model_error\": [1.0, 0.0],\n",
    "}\n",
    "\n",
    "# Selection of basis gate set for transpilation\n",
    "# Note: selector 1 is a hardware agnostic gate set\n",
    "basis_selector = 1\n",
    "basis_gates_array = [\n",
    "    [],\n",
    "    ['rx', 'ry', 'rz', 'cx'],       # a common basis set, default\n",
    "    ['cx', 'rz', 'sx', 'x'],        # IBM default basis set\n",
    "    ['rx', 'ry', 'rxx'],            # IonQ default basis set\n",
    "    ['h', 'p', 'cx'],               # another common basis set\n",
    "    ['u', 'cx']                     # general unitaries basis gates\n",
    "]\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# saved circuits for display\n",
    "QC_ = None\n",
    "Hf_ = None\n",
    "CO_ = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dae35b2-5ad8-4e40-85c0-d520551e7825",
   "metadata": {},
   "outputs": [],
   "source": [
    "################### Circuit Definition #######################################\n",
    "\n",
    "# Construct a Qiskit circuit for VQE Energy evaluation with UCCSD ansatz\n",
    "# param: n_spin_orbs - The number of spin orbitals.\n",
    "# return: return a Qiskit circuit for this VQE ansatz\n",
    "def VQEEnergy(n_spin_orbs, na, nb, circuit_id=0, method=1):\n",
    "\n",
    "    # number of alpha spin orbitals\n",
    "    norb_a = int(n_spin_orbs / 2)\n",
    "\n",
    "    # construct the Hamiltonian\n",
    "    qubit_op = ReadHamiltonian(n_spin_orbs)\n",
    "\n",
    "    # allocate qubits\n",
    "    num_qubits = n_spin_orbs\n",
    "\n",
    "    qr = QuantumRegister(num_qubits)\n",
    "    qc = QuantumCircuit(qr, name=f\"vqe-ansatz({method})-{num_qubits}-{circuit_id}\")\n",
    "\n",
    "    # initialize the HF state\n",
    "    Hf = HartreeFock(num_qubits, na, nb)\n",
    "    qc.append(Hf, qr)\n",
    "\n",
    "    # form the list of single and double excitations \n",
    "    excitationList = []\n",
    "    for occ_a in range(na):\n",
    "        for vir_a in range(na, norb_a):\n",
    "            excitationList.append((occ_a, vir_a))\n",
    "\n",
    "    for occ_b in range(norb_a, norb_a+nb):\n",
    "        for vir_b in range(norb_a+nb, n_spin_orbs):\n",
    "            excitationList.append((occ_b, vir_b))\n",
    "\n",
    "    for occ_a in range(na):\n",
    "        for vir_a in range(na, norb_a):\n",
    "            for occ_b in range(norb_a, norb_a+nb):\n",
    "                for vir_b in range(norb_a+nb, n_spin_orbs):\n",
    "                    excitationList.append((occ_a, vir_a, occ_b, vir_b))\n",
    "\n",
    "    # get cluster operators in Paulis\n",
    "    pauli_list = readPauliExcitation(n_spin_orbs, circuit_id)\n",
    "\n",
    "    # loop over the Pauli operators\n",
    "    for index, PauliOp in enumerate(pauli_list):\n",
    "        # get circuit for exp(-iP)\n",
    "        cluster_qc = ClusterOperatorCircuit(PauliOp, excitationList[index])\n",
    "\n",
    "        # add to ansatz\n",
    "        qc.append(cluster_qc, [i for i in range(cluster_qc.num_qubits)])\n",
    "        \n",
    "    # method 1, only compute the last term in the Hamiltonian\n",
    "    if method == 1:\n",
    "        # last term in Hamiltonian\n",
    "        qc_with_mea, is_diag = ExpectationCircuit(qc, qubit_op[1], num_qubits)\n",
    "\n",
    "        # return the circuit\n",
    "        return qc_with_mea\n",
    "\n",
    "    # now we need to add the measurement parts to the circuit\n",
    "    # circuit list \n",
    "    qc_list = []\n",
    "    diag = []\n",
    "    off_diag = []\n",
    "    global normalization\n",
    "    normalization = 0.0\n",
    "\n",
    "    # add the first non-identity term\n",
    "    identity_qc = qc.copy()\n",
    "    identity_qc.measure_all()\n",
    "    qc_list.append(identity_qc) # add to circuit list\n",
    "    diag.append(qubit_op[1])\n",
    "    normalization += abs(qubit_op[1].coeffs[0]) # add to normalization factor\n",
    "    diag_coeff = abs(qubit_op[1].coeffs[0]) # add to coefficients of diagonal terms\n",
    "\n",
    "    # loop over rest of terms \n",
    "    for index, p in enumerate(qubit_op[2:]):\n",
    "        \n",
    "        # get the circuit with expectation measurements\n",
    "        qc_with_mea, is_diag = ExpectationCircuit(qc, p, num_qubits)\n",
    "\n",
    "        # accumulate normalization \n",
    "        normalization += abs(p.coeffs[0])\n",
    "\n",
    "        # add to circuit list if non-diagonal\n",
    "        if not is_diag:\n",
    "            qc_list.append(qc_with_mea)\n",
    "        else:\n",
    "            diag_coeff += abs(p.coeffs[0])\n",
    "\n",
    "        # diagonal term\n",
    "        if is_diag:\n",
    "            diag.append(p)\n",
    "        # off-diagonal term\n",
    "        else:\n",
    "            off_diag.append(p)\n",
    "\n",
    "    # modify the name of diagonal circuit\n",
    "    qc_list[0].name = qubit_op[1].primitive.to_list()[0][0] + \" \" + str(np.real(diag_coeff))\n",
    "    normalization /= len(qc_list)\n",
    "    return qc_list\n",
    "\n",
    "# Function that constructs the circuit for a given cluster operator\n",
    "def ClusterOperatorCircuit(pauli_op, excitationIndex):\n",
    "    \n",
    "    # compute exp(-iP)\n",
    "    exp_ip = pauli_op.exp_i()\n",
    "\n",
    "    # Trotter approximation\n",
    "    qc_op = PauliTrotterEvolution(trotter_mode=Suzuki(order=1, reps=1)).convert(exp_ip)\n",
    "\n",
    "    # convert to circuit\n",
    "    qc = qc_op.to_circuit(); qc.name = f'Cluster Op {excitationIndex}'\n",
    "    global CO_\n",
    "    if CO_ == None or qc.num_qubits <= 4:\n",
    "        if qc.num_qubits < 7: CO_ = qc\n",
    "\n",
    "    # return this circuit\n",
    "    return qc\n",
    "\n",
    "\n",
    "# Function that adds expectation measurements to the raw circuits\n",
    "def ExpectationCircuit(qc, pauli, nqubit, method=2):\n",
    "\n",
    "    # copy the unrotated circuit\n",
    "    raw_qc = qc.copy()\n",
    "\n",
    "    # whether this term is diagonal\n",
    "    is_diag = True\n",
    "\n",
    "    # primitive Pauli string\n",
    "    PauliString = pauli.primitive.to_list()[0][0]\n",
    "\n",
    "    # coefficient\n",
    "    coeff = pauli.coeffs[0]\n",
    "\n",
    "    # basis rotation\n",
    "    for i, p in enumerate(PauliString):\n",
    "    \n",
    "        target_qubit = nqubit - i - 1 \n",
    "        if (p == \"X\"):\n",
    "            is_diag = False\n",
    "            raw_qc.h(target_qubit)\n",
    "        elif (p == \"Y\"):\n",
    "            raw_qc.sdg(target_qubit)\n",
    "            raw_qc.h(target_qubit)\n",
    "            is_diag = False\n",
    "\n",
    "    # perform measurements\n",
    "    raw_qc.measure_all()\n",
    "\n",
    "    # name of this circuit\n",
    "    raw_qc.name = PauliString + \" \" + str(np.real(coeff))\n",
    "\n",
    "    # save circuit\n",
    "    global QC_\n",
    "    if QC_ == None or nqubit <= 4:\n",
    "        if nqubit < 7: QC_ = raw_qc\n",
    "\n",
    "    return raw_qc, is_diag\n",
    "\n",
    "# Function that implements the Hartree-Fock state \n",
    "def HartreeFock(norb, na, nb):\n",
    "\n",
    "    # initialize the quantum circuit\n",
    "    qc = QuantumCircuit(norb, name=\"Hf\")\n",
    "    \n",
    "    # alpha electrons\n",
    "    for ia in range(na):\n",
    "        qc.x(ia)\n",
    "\n",
    "    # beta electrons\n",
    "    for ib in range(nb):\n",
    "        qc.x(ib+int(norb/2))\n",
    "\n",
    "    # Save smaller circuit\n",
    "    global Hf_\n",
    "    if Hf_ == None or norb <= 4:\n",
    "        if norb < 7: Hf_ = qc\n",
    "\n",
    "    # return the circuit\n",
    "    return qc\n",
    "\n",
    "################ Helper Functions\n",
    "\n",
    "# Function that converts a list of single and double excitation operators to Pauli operators\n",
    "def readPauliExcitation(norb, circuit_id=0):\n",
    "\n",
    "    # load pre-computed data\n",
    "    filename = os.path.join(f'ansatzes/{norb}_qubit_{circuit_id}.txt')\n",
    "    with open(filename) as f:\n",
    "        data = f.read()\n",
    "    ansatz_dict = json.loads(data)\n",
    "\n",
    "    # initialize Pauli list\n",
    "    pauli_list = []\n",
    "\n",
    "    # current coefficients \n",
    "    cur_coeff = 1e5\n",
    "\n",
    "    # current Pauli list \n",
    "    cur_list = []\n",
    "\n",
    "    # loop over excitations\n",
    "    for ext in ansatz_dict:\n",
    "\n",
    "        if cur_coeff > 1e4:\n",
    "            cur_coeff = ansatz_dict[ext]\n",
    "            cur_list = [(ext, ansatz_dict[ext])]\n",
    "        elif abs(abs(ansatz_dict[ext]) - abs(cur_coeff)) > 1e-4:\n",
    "            pauli_list.append(PauliSumOp.from_list(cur_list))\n",
    "            cur_coeff = ansatz_dict[ext]\n",
    "            cur_list = [(ext, ansatz_dict[ext])]\n",
    "        else:\n",
    "            cur_list.append((ext, ansatz_dict[ext]))\n",
    "        \n",
    "    # add the last term\n",
    "    pauli_list.append(PauliSumOp.from_list(cur_list))\n",
    "\n",
    "    # return Pauli list\n",
    "    return pauli_list\n",
    "\n",
    "# Get the Hamiltonian by reading in pre-computed file\n",
    "def ReadHamiltonian(nqubit):\n",
    "\n",
    "    # load pre-computed data\n",
    "    filename = os.path.join( f'Hamiltonians/{nqubit}_qubit.txt')\n",
    "    with open(filename) as f:\n",
    "        data = f.read()\n",
    "    ham_dict = json.loads(data)\n",
    "\n",
    "    # pauli list \n",
    "    pauli_list = []\n",
    "    for p in ham_dict:\n",
    "        pauli_list.append( (p, ham_dict[p]) )\n",
    "\n",
    "    # build Hamiltonian\n",
    "    ham = PauliSumOp.from_list(pauli_list)\n",
    "\n",
    "    # return Hamiltonian\n",
    "    return ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "689e00c0-f6e5-489f-a4d0-670912d5d81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "# DATA ANALYSIS - FIDELITY CALCULATIONS\n",
    "\n",
    "## Uniform distribution function commonly used\n",
    "def rescale_fidelity(fidelity, floor_fidelity, new_floor_fidelity):\n",
    "    \"\"\"\n",
    "    Linearly rescales our fidelities to allow comparisons of fidelities across benchmarks\n",
    "    \n",
    "    fidelity: raw fidelity to rescale\n",
    "    floor_fidelity: threshold fidelity which is equivalent to random guessing\n",
    "    new_floor_fidelity: what we rescale the floor_fidelity to \n",
    "\n",
    "    Ex, with floor_fidelity = 0.25, new_floor_fidelity = 0.0:\n",
    "        1 -> 1;\n",
    "        0.25 -> 0;\n",
    "        0.5 -> 0.3333;\n",
    "    \"\"\"\n",
    "    rescaled_fidelity = (1-new_floor_fidelity)/(1-floor_fidelity) * (fidelity - 1) + 1\n",
    "    \n",
    "    # ensure fidelity is within bounds (0, 1)\n",
    "    if rescaled_fidelity < 0:\n",
    "        rescaled_fidelity = 0.0\n",
    "    if rescaled_fidelity > 1:\n",
    "        rescaled_fidelity = 1.0\n",
    "    \n",
    "    return rescaled_fidelity\n",
    "    \n",
    "def uniform_dist(num_state_qubits):\n",
    "    dist = {}\n",
    "    for i in range(2**num_state_qubits):\n",
    "        key = bin(i)[2:].zfill(num_state_qubits)\n",
    "        dist[key] = 1/(2**num_state_qubits)\n",
    "    return dist                \n",
    "\n",
    "### Analysis methods to be expanded and eventually compiled into a separate analysis.py file\n",
    "import math, functools\n",
    "\n",
    "def hellinger_fidelity_with_expected(p, q):\n",
    "    \"\"\" p: result distribution, may be passed as a counts distribution\n",
    "        q: the expected distribution to be compared against\n",
    "\n",
    "    References:\n",
    "        `Hellinger Distance @ wikipedia <https://en.wikipedia.org/wiki/Hellinger_distance>`_\n",
    "        Qiskit Hellinger Fidelity Function\n",
    "    \"\"\"\n",
    "    p_sum = sum(p.values())\n",
    "    q_sum = sum(q.values())\n",
    "\n",
    "    if q_sum == 0:\n",
    "        print(\"ERROR: polarization_fidelity(), expected distribution is invalid, all counts equal to 0\")\n",
    "        return 0\n",
    "\n",
    "    p_normed = {}\n",
    "    for key, val in p.items():\n",
    "        p_normed[key] = val/p_sum\n",
    "        # if p_sum != 0:\n",
    "        #     p_normed[key] = val/p_sum\n",
    "        # else:\n",
    "        #     p_normed[key] = 0\n",
    "\n",
    "    q_normed = {}\n",
    "    for key, val in q.items():\n",
    "        q_normed[key] = val/q_sum\n",
    "\n",
    "    total = 0\n",
    "    for key, val in p_normed.items():\n",
    "        if key in q_normed.keys():\n",
    "            total += (np.sqrt(val) - np.sqrt(q_normed[key]))**2\n",
    "            del q_normed[key]\n",
    "        else:\n",
    "            total += val\n",
    "    total += sum(q_normed.values())\n",
    "    \n",
    "    # in some situations (error mitigation) this can go negative, use abs value\n",
    "    if total < 0:\n",
    "        print(f\"WARNING: using absolute value in fidelity calculation\")\n",
    "        total = abs(total)\n",
    "        \n",
    "    dist = np.sqrt(total)/np.sqrt(2)\n",
    "    fidelity = (1-dist**2)**2\n",
    "\n",
    "    return fidelity\n",
    "\n",
    "def polarization_fidelity(counts, correct_dist, thermal_dist=None):\n",
    "    \"\"\"\n",
    "    Combines Hellinger fidelity and polarization rescaling into fidelity calculation\n",
    "    used in every benchmark\n",
    "\n",
    "    counts: the measurement outcomes after `num_shots` algorithm runs\n",
    "    correct_dist: the distribution we expect to get for the algorithm running perfectly\n",
    "    thermal_dist: optional distribution to pass in distribution from a uniform\n",
    "                  superposition over all states. If `None`: generated as \n",
    "                  `uniform_dist` with the same qubits as in `counts`\n",
    "                  \n",
    "    returns both polarization fidelity and the hellinger fidelity\n",
    "\n",
    "    Polarization from: `https://arxiv.org/abs/2008.11294v1`\n",
    "    \"\"\"\n",
    "    #print(\"in polarization fidelity:\",correct_dist)\n",
    "    num_measured_qubits = len(list(correct_dist.keys())[0])\n",
    "    print(num_measured_qubits)\n",
    "    \n",
    "    counts = {k.zfill(num_measured_qubits): v for k, v in counts.items()}\n",
    "    \n",
    "    # calculate hellinger fidelity between measured expectation values and correct distribution\n",
    "    hf_fidelity = hellinger_fidelity_with_expected(counts,correct_dist)\n",
    "    \n",
    "    # to limit cpu and memory utilization, skip noise correction if more than 16 measured qubits\n",
    "    if num_measured_qubits > 16:\n",
    "        return { 'fidelity':hf_fidelity, 'hf_fidelity':hf_fidelity }\n",
    "\n",
    "    # if not provided, generate thermal dist based on number of qubits\n",
    "    if thermal_dist == None:\n",
    "        thermal_dist = uniform_dist(num_measured_qubits)\n",
    "\n",
    "    # set our fidelity rescaling value as the hellinger fidelity for a depolarized state\n",
    "    floor_fidelity = hellinger_fidelity_with_expected(thermal_dist, correct_dist)\n",
    "\n",
    "    # rescale fidelity result so uniform superposition (random guessing) returns fidelity\n",
    "    # rescaled to 0 to provide a better measure of success of the algorithm (polarization)\n",
    "    new_floor_fidelity = 0\n",
    "    fidelity = rescale_fidelity(hf_fidelity, floor_fidelity, new_floor_fidelity)\n",
    "\n",
    "    return { 'fidelity':fidelity, 'hf_fidelity':hf_fidelity }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af6fe4e1-36c7-4dc8-8212-9d3bc2375c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate circuit depth\n",
    "def calculate_circuit_depth(qc):\n",
    "    # Calculate the depth of the circuit\n",
    "    depth = qc.depth()\n",
    "    return depth\n",
    "\n",
    "def calculate_transpiled_depth(qc,basis_selector):\n",
    "    # use either the backend or one of the basis gate sets\n",
    "    if basis_selector == 0:\n",
    "        qc = transpile(qc, backend)\n",
    "        \n",
    "    else:\n",
    "        basis_gates = basis_gates_array[basis_selector]\n",
    "        qc = transpile(qc, basis_gates=basis_gates, seed_transpiler=0)\n",
    "    transpiled_depth = qc.depth()\n",
    "    return transpiled_depth\n",
    "\n",
    "def plot_data(fidelity_data, Hf_fidelity_data, title):\n",
    "    avg_fidelity_means = []\n",
    "    avg_Hf_fidelity_means = []\n",
    "    avg_num_qubits_values = list(fidelity_data.keys())\n",
    "    print(\"avg_num_qubits_values\",avg_num_qubits_values)\n",
    "    # Calculate the average fidelity and Hamming fidelity for each unique number of qubits\n",
    "    for num_qubits in avg_num_qubits_values:\n",
    "        avg_fidelity = np.average(fidelity_data[num_qubits])\n",
    "        avg_fidelity_means.append(avg_fidelity)\n",
    "\n",
    "        avg_Hf_fidelity = np.mean(Hf_fidelity_data[num_qubits])\n",
    "        avg_Hf_fidelity_means.append(avg_Hf_fidelity)\n",
    "    \n",
    "    \n",
    "\n",
    "    # Plot the data\n",
    "    x = np.arange(len(avg_num_qubits_values))\n",
    "    \n",
    "    width = 0.35\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    rects2 =ax.bar(x, avg_Hf_fidelity_means, width=0.4, label='Hellinger Fidelity',color=\"magenta\")\n",
    "    rects1 = ax.bar(x, avg_fidelity_means, width=0.2, label='Normalized Fidelity', color=\"blue\")\n",
    "    \n",
    "    ax.set_xlabel('Number of Qubits')\n",
    "    ax.set_ylabel('Average Value')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(avg_num_qubits_values)\n",
    "    ax.legend()\n",
    "    \n",
    "    # Add labels to the bars\n",
    "    def autolabel(rects):\n",
    "        for rect in rects:\n",
    "            height = rect.get_height()\n",
    "            ax.annotate('{:.5f}'.format(height),  # Formatting to two decimal places\n",
    "                        xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                        xytext=(0, 3),\n",
    "                        textcoords=\"offset points\",\n",
    "                        ha='center', va='bottom')\n",
    "    \n",
    "    autolabel(rects1)\n",
    "    autolabel(rects2)\n",
    "    \n",
    "    plt.show()\n",
    "    return avg_fidelity_means\n",
    "    # print(fidelity_data)\n",
    "    # print(Hf_fidelity_data)\n",
    "    # print(avg_fidelity_means)\n",
    "    # print(avg_Hf_fidelity_means)\n",
    "\n",
    "backend = BasicAer.get_backend('dm_simulator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "443c3df1-92aa-4542-bca3-895e5a08c852",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Rectangle\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap, Normalize\n",
    "from matplotlib.patches import Circle\n",
    "\n",
    "############### Color Map functions\n",
    " \n",
    "# Create a selection of colormaps from which to choose; default to custom_spectral\n",
    "cmap_spectral = plt.get_cmap('Spectral')\n",
    "cmap_greys = plt.get_cmap('Greys')\n",
    "cmap_blues = plt.get_cmap('Blues')\n",
    "cmap_custom_spectral = None\n",
    "\n",
    "# the default colormap is the spectral map\n",
    "cmap = cmap_spectral\n",
    "cmap_orig = cmap_spectral\n",
    "\n",
    "# current cmap normalization function (default None)\n",
    "cmap_norm = None\n",
    "\n",
    "default_fade_low_fidelity_level = 0.16\n",
    "default_fade_rate = 0.7\n",
    "\n",
    "# Specify a normalization function here (default None)\n",
    "def set_custom_cmap_norm(vmin, vmax):\n",
    "\n",
    "    global cmap_norm\n",
    "    \n",
    "    if vmin == vmax or (vmin == 0.0 and vmax == 1.0):\n",
    "        print(\"... setting cmap norm to None\")\n",
    "        cmap_norm = None\n",
    "    else:\n",
    "        print(f\"... setting cmap norm to [{vmin}, {vmax}]\")\n",
    "        cmap_norm = Normalize(vmin=vmin, vmax=vmax)\n",
    "    \n",
    "# Remake the custom spectral colormap with user settings\n",
    "def set_custom_cmap_style(\n",
    "            fade_low_fidelity_level=default_fade_low_fidelity_level,\n",
    "            fade_rate=default_fade_rate):\n",
    "            \n",
    "    #print(\"... set custom map style\")\n",
    "    global cmap, cmap_custom_spectral, cmap_orig\n",
    "    cmap_custom_spectral = create_custom_spectral_cmap(\n",
    "                fade_low_fidelity_level=fade_low_fidelity_level, fade_rate=fade_rate)\n",
    "    cmap = cmap_custom_spectral\n",
    "    cmap_orig = cmap_custom_spectral\n",
    "       \n",
    "# Create the custom spectral colormap from the base spectral\n",
    "def create_custom_spectral_cmap(\n",
    "            fade_low_fidelity_level=default_fade_low_fidelity_level,\n",
    "            fade_rate=default_fade_rate):\n",
    "\n",
    "    # determine the breakpoint from the fade level\n",
    "    num_colors = 100\n",
    "    breakpoint = round(fade_low_fidelity_level * num_colors)\n",
    "    \n",
    "    # get color list for spectral map\n",
    "    spectral_colors = [cmap_spectral(v/num_colors) for v in range(num_colors)]\n",
    "\n",
    "    #print(fade_rate)\n",
    "    \n",
    "    # create a list of colors to replace those below the breakpoint\n",
    "    # and fill with \"faded\" color entries (in reverse)\n",
    "    low_colors = [0] * breakpoint\n",
    "    #for i in reversed(range(breakpoint)):\n",
    "    for i in range(breakpoint):\n",
    "    \n",
    "        # x is index of low colors, normalized 0 -> 1\n",
    "        x = i / breakpoint\n",
    "    \n",
    "        # get color at this index\n",
    "        bc = spectral_colors[i]\n",
    "        r0 = bc[0]\n",
    "        g0 = bc[1]\n",
    "        b0 = bc[2]\n",
    "        z0 = bc[3]\n",
    "        \n",
    "        r_delta = 0.92 - r0\n",
    "        \n",
    "        #print(f\"{x} {bc} {r_delta}\")\n",
    "         \n",
    "        # compute saturation and greyness ratio\n",
    "        sat_ratio = 1 - x\n",
    "        \n",
    "        #grey_ratio = 1 - x\n",
    "        '''  attempt at a reflective gradient   \n",
    "        if i >= breakpoint/2:\n",
    "            xf = 2*(x - 0.5)\n",
    "            yf = pow(xf, 1/fade_rate)/2\n",
    "            grey_ratio = 1 - (yf + 0.5)\n",
    "        else:\n",
    "            xf = 2*(0.5 - x)\n",
    "            yf = pow(xf, 1/fade_rate)/2\n",
    "            grey_ratio = 1 - (0.5 - yf)\n",
    "        '''   \n",
    "        grey_ratio = 1 - math.pow(x, 1/fade_rate)\n",
    "        \n",
    "        #print(f\"  {xf} {yf} \")\n",
    "        #print(f\"  {sat_ratio} {grey_ratio}\")\n",
    "\n",
    "        r = r0 + r_delta * sat_ratio\n",
    "        \n",
    "        g_delta = r - g0\n",
    "        b_delta = r - b0\n",
    "        g = g0 + g_delta * grey_ratio\n",
    "        b = b0 + b_delta * grey_ratio \n",
    "            \n",
    "        #print(f\"{r} {g} {b}\\n\")    \n",
    "        low_colors[i] = (r,g,b,z0)\n",
    "        \n",
    "    #print(low_colors)\n",
    "\n",
    "    # combine the faded low colors with the regular spectral cmap to make a custom version\n",
    "    cmap_custom_spectral = ListedColormap(low_colors + spectral_colors[breakpoint:])\n",
    "\n",
    "    #spectral_colors = [cmap_custom_spectral(v/10) for v in range(10)]\n",
    "    #for i in range(10): print(spectral_colors[i])\n",
    "    #print(\"\")\n",
    "    \n",
    "    return cmap_custom_spectral\n",
    "\n",
    "# Make the custom spectral color map the default on module init\n",
    "set_custom_cmap_style()\n",
    "\n",
    "# Arrange the stored annotations optimally and add to plot \n",
    "def anno_volumetric_data(ax, depth_base=2, label='Depth',\n",
    "        labelpos=(0.2, 0.7), labelrot=0, type=1, fill=True):\n",
    "    \n",
    "    # sort all arrays by the x point of the text (anno_offs)\n",
    "    global x_anno_offs, y_anno_offs, anno_labels, x_annos, y_annos\n",
    "    all_annos = sorted(zip(x_anno_offs, y_anno_offs, anno_labels, x_annos, y_annos))\n",
    "    x_anno_offs = [a for a,b,c,d,e in all_annos]\n",
    "    y_anno_offs = [b for a,b,c,d,e in all_annos]\n",
    "    anno_labels = [c for a,b,c,d,e in all_annos]\n",
    "    x_annos = [d for a,b,c,d,e in all_annos]\n",
    "    y_annos = [e for a,b,c,d,e in all_annos]\n",
    "    \n",
    "    #print(f\"{x_anno_offs}\")\n",
    "    #print(f\"{y_anno_offs}\")\n",
    "    #print(f\"{anno_labels}\")\n",
    "    \n",
    "    for i in range(len(anno_labels)):\n",
    "        x_anno = x_annos[i]\n",
    "        y_anno = y_annos[i]\n",
    "        x_anno_off = x_anno_offs[i]\n",
    "        y_anno_off = y_anno_offs[i]\n",
    "        label = anno_labels[i]\n",
    "        \n",
    "        if i > 0:\n",
    "            x_delta = abs(x_anno_off - x_anno_offs[i - 1])\n",
    "            y_delta = abs(y_anno_off - y_anno_offs[i - 1])\n",
    "            \n",
    "            if y_delta < 0.7 and x_delta < 2:\n",
    "                y_anno_off = y_anno_offs[i] = y_anno_offs[i - 1] - 0.6\n",
    "                #x_anno_off = x_anno_offs[i] = x_anno_offs[i - 1] + 0.1\n",
    "                    \n",
    "        ax.annotate(label,\n",
    "            xy=(x_anno+0.0, y_anno+0.1),\n",
    "            arrowprops=dict(facecolor='black', shrink=0.0,\n",
    "                width=0.5, headwidth=4, headlength=5, edgecolor=(0.8,0.8,0.8)),\n",
    "            xytext=(x_anno_off + labelpos[0], y_anno_off + labelpos[1]),\n",
    "            rotation=labelrot,\n",
    "            horizontalalignment='left', verticalalignment='baseline',\n",
    "            color=(0.2,0.2,0.2),\n",
    "            clip_on=True)\n",
    "\n",
    "# Plot one group of data for volumetric presentation    \n",
    "def plot_volumetric_data(ax, w_data, d_data, f_data, depth_base=2, label='Depth',\n",
    "        labelpos=(0.2, 0.7), labelrot=0, type=1, fill=True, w_max=18, do_label=False, do_border=True,\n",
    "        x_size=1.0, y_size=1.0, zorder=1, offset_flag=False,\n",
    "        max_depth=0, suppress_low_fidelity=False):\n",
    "\n",
    "    # since data may come back out of order, save point at max y for annotation\n",
    "    i_anno = 0\n",
    "    x_anno = 0 \n",
    "    y_anno = 0\n",
    "    \n",
    "    # plot data rectangles\n",
    "    low_fidelity_count = True\n",
    "    \n",
    "    last_y = -1\n",
    "    k = 0\n",
    "\n",
    "    # determine y-axis dimension for one pixel to use for offset of bars that start at 0\n",
    "    (_, dy) = get_pixel_dims(ax)\n",
    "    \n",
    "    # do this loop in reverse to handle the case where earlier cells are overlapped by later cells\n",
    "    for i in reversed(range(len(d_data))):\n",
    "        x = depth_index(d_data[i], depth_base)\n",
    "        y = float(w_data[i])\n",
    "        f = f_data[i]\n",
    "        \n",
    "        # each time we star a new row, reset the offset counter\n",
    "        # DEVNOTE: this is highly specialized for the QA area plots, where there are 8 bars\n",
    "        # that represent time starting from 0 secs.  We offset by one pixel each and center the group\n",
    "        if y != last_y:\n",
    "            last_y = y;\n",
    "            k = 3              # hardcoded for 8 cells, offset by 3\n",
    "        \n",
    "        #print(f\"{i = } {x = } {y = }\")\n",
    "        \n",
    "        if max_depth > 0 and d_data[i] > max_depth:\n",
    "            #print(f\"... excessive depth (2), skipped; w={y} d={d_data[i]}\")\n",
    "            break;\n",
    "            \n",
    "        # reject cells with low fidelity\n",
    "        if suppress_low_fidelity and f < suppress_low_fidelity_level:\n",
    "            if low_fidelity_count: break\n",
    "            else: low_fidelity_count = True\n",
    "        \n",
    "        # the only time this is False is when doing merged gradation plots\n",
    "        if do_border == True:\n",
    "        \n",
    "            # this case is for an array of x_sizes, i.e. each box has different width\n",
    "            if isinstance(x_size, list):\n",
    "                \n",
    "                # draw each of the cells, with no offset\n",
    "                if not offset_flag:\n",
    "                    ax.add_patch(box_at(x, y, f, type=type, fill=fill, x_size=x_size[i], y_size=y_size, zorder=zorder))\n",
    "                    \n",
    "                # use an offset for y value, AND account for x and width to draw starting at 0\n",
    "                else:\n",
    "                    ax.add_patch(box_at((x/2 + x_size[i]/4), y + k*dy, f, type=type, fill=fill, x_size=x+ x_size[i]/2, y_size=y_size, zorder=zorder))\n",
    "                \n",
    "            # this case is for only a single cell\n",
    "            else:\n",
    "                ax.add_patch(box_at(x, y, f, type=type, fill=fill, x_size=x_size, y_size=y_size))\n",
    "\n",
    "        # save the annotation point with the largest y value\n",
    "        if y >= y_anno:\n",
    "            x_anno = x\n",
    "            y_anno = y\n",
    "            i_anno = i\n",
    "        \n",
    "        # move the next bar down (if using offset)\n",
    "        k -= 1\n",
    "    \n",
    "    # if no data rectangles plotted, no need for a label\n",
    "    if x_anno == 0 or y_anno == 0:\n",
    "        return\n",
    "        \n",
    "    x_annos.append(x_anno)\n",
    "    y_annos.append(y_anno)\n",
    "    \n",
    "    anno_dist = math.sqrt( (y_anno - 1)**2 + (x_anno - 1)**2 )\n",
    "    \n",
    "    # adjust radius of annotation circle based on maximum width of apps\n",
    "    anno_max = 10\n",
    "    if w_max > 10:\n",
    "        anno_max = 14\n",
    "    if w_max > 14:\n",
    "        anno_max = 18\n",
    "        \n",
    "    scale = anno_max / anno_dist\n",
    "\n",
    "    # offset of text from end of arrow\n",
    "    if scale > 1:\n",
    "        x_anno_off = scale * x_anno - x_anno - 0.5\n",
    "        y_anno_off = scale * y_anno - y_anno\n",
    "    else:\n",
    "        x_anno_off = 0.7\n",
    "        y_anno_off = 0.5\n",
    "        \n",
    "    x_anno_off += x_anno\n",
    "    y_anno_off += y_anno\n",
    "    \n",
    "    # print(f\"... {xx} {yy} {anno_dist}\")\n",
    "    x_anno_offs.append(x_anno_off)\n",
    "    y_anno_offs.append(y_anno_off)\n",
    "    \n",
    "    anno_labels.append(label)\n",
    "    \n",
    "    if do_label:\n",
    "        ax.annotate(label, xy=(x_anno+labelpos[0], y_anno+labelpos[1]), rotation=labelrot,\n",
    "            horizontalalignment='left', verticalalignment='bottom', color=(0.2,0.2,0.2))\n",
    "\n",
    "x_annos = []\n",
    "y_annos = []\n",
    "x_anno_offs = []\n",
    "y_anno_offs = []\n",
    "anno_labels = []\n",
    "    \n",
    "# init arrays to hold annotation points for label spreading\n",
    "def vplot_anno_init ():\n",
    "\n",
    "    global x_annos, y_annos, x_anno_offs, y_anno_offs, anno_labels\n",
    "    \n",
    "    x_annos = []\n",
    "    y_annos = []\n",
    "    x_anno_offs = []\n",
    "    y_anno_offs = []\n",
    "    anno_labels = []\n",
    "\n",
    "# Number of ticks on volumetric depth axis\n",
    "max_depth_log = 22\n",
    "\n",
    "# average transpile factor between base QV depth and our depth based on results from QV notebook\n",
    "QV_transpile_factor = 12.7 \n",
    "\n",
    "# format a number using K,M,B,T for large numbers, optionally rounding to 'digits' decimal places if num > 1\n",
    "# (sign handling may be incorrect)\n",
    "def format_number(num, digits=0):\n",
    "    if isinstance(num, str): num = float(num)\n",
    "    num = float('{:.3g}'.format(abs(num)))\n",
    "    sign = ''\n",
    "    metric = {'T': 1000000000000, 'B': 1000000000, 'M': 1000000, 'K': 1000, '': 1}\n",
    "    for index in metric:\n",
    "        num_check = num / metric[index]\n",
    "        if num_check >= 1:\n",
    "            num = round(num_check, digits)\n",
    "            sign = index\n",
    "            break\n",
    "    numstr = f\"{str(num)}\"\n",
    "    if '.' in numstr:\n",
    "        numstr = numstr.rstrip('0').rstrip('.')\n",
    "    return f\"{numstr}{sign}\"\n",
    "\n",
    "# Return the color associated with the spcific value, using color map norm\n",
    "def get_color(value):\n",
    "    \n",
    "    # if there is a normalize function installed, scale the data\n",
    "    if cmap_norm:\n",
    "        value = float(cmap_norm(value))\n",
    "        \n",
    "    if cmap == cmap_spectral:\n",
    "        value = 0.05 + value*0.9\n",
    "    elif cmap == cmap_blues:\n",
    "        value = 0.00 + value*1.0\n",
    "    else:\n",
    "        value = 0.0 + value*0.95\n",
    "        \n",
    "    return cmap(value)\n",
    "\n",
    "# Return the x and y equivalent to a single pixel for the given plot axis\n",
    "def get_pixel_dims(ax):\n",
    "\n",
    "    # transform 0 -> 1 to pixel dimensions\n",
    "    pixdims = ax.transData.transform([(0,1),(1,0)])-ax.transData.transform((0,0))\n",
    "    xpix = pixdims[1][0]\n",
    "    ypix = pixdims[0][1]\n",
    "    \n",
    "    #determine x- and y-axis dimension for one pixel \n",
    "    dx = (1 / xpix)\n",
    "    dy = (1 / ypix)\n",
    "    \n",
    "    return (dx, dy)\n",
    "\n",
    "############### Helper functions\n",
    " \n",
    "# return the base index for a circuit depth value\n",
    "# take the log in the depth base, and add 1\n",
    "def depth_index(d, depth_base):\n",
    "    if depth_base <= 1:\n",
    "        return d\n",
    "    if d == 0:\n",
    "        return 0\n",
    "    return math.log(d, depth_base) + 1\n",
    "\n",
    "# draw a box at x,y with various attributes   \n",
    "def box_at(x, y, value, type=1, fill=True, x_size=1.0, y_size=1.0, alpha=1.0, zorder=1):\n",
    "    \n",
    "    value = min(value, 1.0)\n",
    "    value = max(value, 0.0)\n",
    "\n",
    "    fc = get_color(value)\n",
    "    ec = (0.5,0.5,0.5)\n",
    "    \n",
    "    return Rectangle((x - (x_size/2), y - (y_size/2)), x_size, y_size,\n",
    "             alpha=alpha,\n",
    "             edgecolor = ec,\n",
    "             facecolor = fc,\n",
    "             fill=fill,\n",
    "             lw=0.5*y_size,\n",
    "             zorder=zorder)\n",
    "\n",
    "# draw a circle at x,y with various attributes \n",
    "def circle_at(x, y, value, type=1, fill=True):\n",
    "    size = 1.0\n",
    "    \n",
    "    value = min(value, 1.0)\n",
    "    value = max(value, 0.0)\n",
    "\n",
    "    fc = get_color(value)\n",
    "    ec = (0.5,0.5,0.5)\n",
    "    \n",
    "    return Circle((x, y), size/2,\n",
    "             alpha = 0.7,                       # DEVNOTE: changed to 0.7 from 0.5, to handle only one cell\n",
    "             edgecolor = ec,\n",
    "             facecolor = fc,\n",
    "             fill=fill,\n",
    "             lw=0.5)\n",
    "             \n",
    "def box4_at(x, y, value, type=1, fill=True, alpha=1.0):\n",
    "    size = 1.0\n",
    "    \n",
    "    value = min(value, 1.0)\n",
    "    value = max(value, 0.0)\n",
    "\n",
    "    fc = get_color(value)\n",
    "    ec = (0.3,0.3,0.3)\n",
    "    ec = fc\n",
    "    \n",
    "    return Rectangle((x - size/8, y - size/2), size/4, size,\n",
    "             alpha=alpha,\n",
    "             edgecolor = ec,\n",
    "             facecolor = fc,\n",
    "             fill=fill,\n",
    "             lw=0.1)\n",
    "\n",
    "# Draw a Quantum Volume rectangle with specified width and depth, and grey-scale value \n",
    "def qv_box_at(x, y, qv_width, qv_depth, value, depth_base):\n",
    "    #print(f\"{qv_width} {qv_depth} {depth_index(qv_depth, depth_base)}\")\n",
    "    return Rectangle((x - 0.5, y - 0.5), depth_index(qv_depth, depth_base), qv_width,\n",
    "             edgecolor = (value,value,value),\n",
    "             facecolor = (value,value,value),\n",
    "             fill=True,\n",
    "             lw=1)\n",
    "\n",
    "def bkg_box_at(x, y, value=0.9):\n",
    "    size = 0.6\n",
    "    return Rectangle((x - size/2, y - size/2), size, size,\n",
    "             edgecolor = (.75,.75,.75),\n",
    "             facecolor = (value,value,value),\n",
    "             fill=True,\n",
    "             lw=0.5)\n",
    "             \n",
    "def bkg_empty_box_at(x, y):\n",
    "    size = 0.6\n",
    "    return Rectangle((x - size/2, y - size/2), size, size,\n",
    "             edgecolor = (.75,.75,.75),\n",
    "             facecolor = (1.0,1.0,1.0),\n",
    "             fill=True,\n",
    "             lw=0.5)\n",
    "\n",
    "# Plot the background for the volumetric analysis    \n",
    "def plot_volumetric_background(max_qubits=11, QV=32, depth_base=2, suptitle=None, avail_qubits=0, colorbar_label=\"Avg Result Fidelity\"):\n",
    "\n",
    "    if suptitle == None:\n",
    "        suptitle = f\"Volumetric Positioning\\nCircuit Dimensions and Fidelity Overlaid on Quantum Volume = {QV}\"\n",
    "\n",
    "    QV0 = QV\n",
    "    qv_estimate = False\n",
    "    est_str = \"\"\n",
    "    if QV == 0:                 # QV = 0 indicates \"do not draw QV background or label\"\n",
    "        QV = 2048\n",
    "        \n",
    "    elif QV < 0:                # QV < 0 indicates \"add est. to label\"\n",
    "        QV = -QV\n",
    "        qv_estimate = True\n",
    "        est_str = \" (est.)\"\n",
    "        \n",
    "    if avail_qubits > 0 and max_qubits > avail_qubits:\n",
    "        max_qubits = avail_qubits\n",
    "        \n",
    "    max_width = 13\n",
    "    if max_qubits > 11: max_width = 18\n",
    "    if max_qubits > 14: max_width = 20\n",
    "    if max_qubits > 16: max_width = 24\n",
    "    #print(f\"... {avail_qubits} {max_qubits} {max_width}\")\n",
    "    \n",
    "    plot_width = 6.8\n",
    "    plot_height = 0.5 + plot_width * (max_width / max_depth_log)\n",
    "    #print(f\"... {plot_width} {plot_height}\")\n",
    "    \n",
    "    # define matplotlib figure and axis; use constrained layout to fit colorbar to right\n",
    "    fig, ax = plt.subplots(figsize=(plot_width, plot_height), constrained_layout=True)\n",
    "\n",
    "    plt.suptitle(suptitle)\n",
    "\n",
    "    plt.xlim(0, max_depth_log)\n",
    "    plt.ylim(0, max_width)\n",
    "\n",
    "    # circuit depth axis (x axis)\n",
    "    xbasis = [x for x in range(1,max_depth_log)]\n",
    "    xround = [depth_base**(x-1) for x in xbasis]\n",
    "    xlabels = [format_number(x) for x in xround]\n",
    "    ax.set_xlabel('Circuit Depth')\n",
    "    ax.set_xticks(xbasis)  \n",
    "    plt.xticks(xbasis, xlabels, color='black', rotation=45, ha='right', va='top', rotation_mode=\"anchor\")\n",
    "    \n",
    "    # other label options\n",
    "    #plt.xticks(xbasis, xlabels, color='black', rotation=-60, ha='left')\n",
    "    #plt.xticks(xbasis, xlabels, color='black', rotation=-45, ha='left', va='center', rotation_mode=\"anchor\")\n",
    "\n",
    "    # circuit width axis (y axis)\n",
    "    ybasis = [y for y in range(1,max_width)]\n",
    "    yround = [1,2,3,4,5,6,7,8,10,12,15]     # not used now\n",
    "    ylabels = [str(y) for y in yround]      # not used now \n",
    "    #ax.set_ylabel('Circuit Width (Number of Qubits)')\n",
    "    ax.set_ylabel('Circuit Width')\n",
    "    ax.set_yticks(ybasis)\n",
    "\n",
    "    #create simple line plot (not used right now)\n",
    "    #ax.plot([0, 10],[0, 10])\n",
    "    \n",
    "    log2QV = math.log2(QV)\n",
    "    QV_width = log2QV\n",
    "    QV_depth = log2QV * QV_transpile_factor\n",
    "    \n",
    "    # show a quantum volume rectangle of QV = 64 e.g. (6 x 6)\n",
    "    if QV0 != 0:\n",
    "        ax.add_patch(qv_box_at(1, 1, QV_width, QV_depth, 0.87, depth_base))\n",
    "    else:\n",
    "        ax.add_patch(qv_box_at(1, 1, QV_width, QV_depth, 0.91, depth_base))\n",
    "    \n",
    "    # the untranspiled version is commented out - we do not show this by default\n",
    "    # also show a quantum volume rectangle un-transpiled\n",
    "    # ax.add_patch(qv_box_at(1, 1, QV_width, QV_width, 0.80, depth_base))\n",
    "\n",
    "    # show 2D array of volumetric cells based on this QV_transpiled\n",
    "    # DEVNOTE: we use +1 only to make the visuals work; s/b without\n",
    "    # Also, the second arg of the min( below seems incorrect, needs correction\n",
    "    maxprod = (QV_width + 1) * (QV_depth + 1)\n",
    "    for w in range(1, min(max_width, round(QV) + 1)):\n",
    "        \n",
    "        # don't show VB squares if width greater than known available qubits\n",
    "        if avail_qubits != 0 and w > avail_qubits:\n",
    "            continue\n",
    "        \n",
    "        i_success = 0\n",
    "        for d in xround:\n",
    "        \n",
    "            # polarization factor for low circuit widths\n",
    "            maxtest = maxprod / ( 1 - 1 / (2**w) )\n",
    "            \n",
    "            # if circuit would fail here, don't draw box\n",
    "            if d > maxtest: continue\n",
    "            if w * d > maxtest: continue\n",
    "            \n",
    "            # guess for how to capture how hardware decays with width, not entirely correct\n",
    "\n",
    "            # # reduce maxtext by a factor of number of qubits > QV_width\n",
    "            # # just an approximation to account for qubit distances\n",
    "            # if w > QV_width:\n",
    "            #     over = w - QV_width \n",
    "            #     maxtest = maxtest / (1 + (over/QV_width))\n",
    "\n",
    "            # draw a box at this width and depth\n",
    "            id = depth_index(d, depth_base) \n",
    "            \n",
    "            # show vb rectangles; if not showing QV, make all hollow (or less dark)\n",
    "            if QV0 == 0:\n",
    "                #ax.add_patch(bkg_empty_box_at(id, w))\n",
    "                ax.add_patch(bkg_box_at(id, w, 0.95))\n",
    "            \n",
    "            else:\n",
    "                ax.add_patch(bkg_box_at(id, w, 0.9))\n",
    "            \n",
    "            # save index of last successful depth\n",
    "            i_success += 1\n",
    "        \n",
    "        # plot empty rectangle after others       \n",
    "        d = xround[i_success]\n",
    "        id = depth_index(d, depth_base) \n",
    "        ax.add_patch(bkg_empty_box_at(id, w))\n",
    "        \n",
    "    \n",
    "    # Add annotation showing quantum volume\n",
    "    if QV0 != 0:\n",
    "        t = ax.text(max_depth_log - 2.0, 1.5, f\"QV{est_str}={QV}\", size=12,\n",
    "                horizontalalignment='right', verticalalignment='center', color=(0.2,0.2,0.2),\n",
    "                bbox=dict(boxstyle=\"square,pad=0.3\", fc=(.9,.9,.9), ec=\"grey\", lw=1))\n",
    "                \n",
    "    # add colorbar to right of plot\n",
    "    plt.colorbar(cm.ScalarMappable(cmap=cmap), cax=None, ax=ax,\n",
    "            shrink=0.6, label=colorbar_label, panchor=(0.0, 0.7))\n",
    "            \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "409ea2c7-52a2-4c02-9cc6-91fbe42c004c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************\n",
      "Executing [17] circuits with num_qubits = 4\n",
      "qc of 4 qubits of type <class 'type'>\n",
      "        ┌─────┐┌────────────────────┐┌────────────────────┐»\n",
      "  q0_0: ┤0    ├┤0                   ├┤0                   ├»\n",
      "        │     ││                    ││                    │»\n",
      "  q0_1: ┤1    ├┤1                   ├┤1                   ├»\n",
      "        │  Hf ││  Cluster Op (0, 1) ││  Cluster Op (2, 3) │»\n",
      "  q0_2: ┤2    ├┤2                   ├┤2                   ├»\n",
      "        │     ││                    ││                    │»\n",
      "  q0_3: ┤3    ├┤3                   ├┤3                   ├»\n",
      "        └─────┘└────────────────────┘└────────────────────┘»\n",
      "meas: 4/═══════════════════════════════════════════════════»\n",
      "                                                           »\n",
      "«        ┌──────────────────────────┐ ░ ┌─┐         \n",
      "«  q0_0: ┤0                         ├─░─┤M├─────────\n",
      "«        │                          │ ░ └╥┘┌─┐      \n",
      "«  q0_1: ┤1                         ├─░──╫─┤M├──────\n",
      "«        │  Cluster Op (0, 1, 2, 3) │ ░  ║ └╥┘┌─┐   \n",
      "«  q0_2: ┤2                         ├─░──╫──╫─┤M├───\n",
      "«        │                          │ ░  ║  ║ └╥┘┌─┐\n",
      "«  q0_3: ┤3                         ├─░──╫──╫──╫─┤M├\n",
      "«        └──────────────────────────┘ ░  ║  ║  ║ └╥┘\n",
      "«meas: 4/════════════════════════════════╩══╩══╩══╩═\n",
      "«                                        0  1  2  3 \n",
      "prob {'0000': 0.0, '0001': 0.0, '0010': 0.0, '0011': 0.0, '0100': 0.0, '0101': 0.129638671875, '0110': 0.81689453125, '0111': 0.0, '1000': 0.0, '1001': 0.005615234375, '1010': 0.0478515625, '1011': 0.0, '1100': 0.0, '1101': 0.0, '1110': 0.0, '1111': 0.0}\n",
      "counts= {'0000': 0, '0001': 0, '0010': 0, '0011': 0, '0100': 0, '0101': 530, '0110': 3342, '0111': 0, '1000': 0, '1001': 22, '1010': 195, '1011': 0, '1100': 0, '1101': 0, '1110': 0, '1111': 0}\n",
      "total name ============ ZIII 1.0882399999999999\n",
      "pauli_string =============== ZIII\n",
      "len(total_name) ===== 2\n",
      "correct_dist : {'0101': 0.04757854502688172, '0110': 0.8172291208455523, '1001': 0.00553862719941349, '1010': 0.12965370692815248}\n",
      "4\n",
      "fidelity_dict : {'fidelity': 0.9530854883742724, 'hf_fidelity': 0.9601903786463596}\n",
      "abs(float(total_name.split()[1])) / normalization ========== 13.192857346606944\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'dict' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-32514b23a0c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;31m# Execute the benchmark program, accumulate metrics, and calculate circuit depths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m \u001b[0mcreation_times\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melapsed_times\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquantum_times\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcircuit_depths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtranspiled_depths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfidelity_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHf_fidelity_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-32514b23a0c5>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(min_qubits, max_qubits, skip_qubits, max_circuits, num_shots, method)\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"abs(float(total_name.split()[1])) / normalization ==========\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnormalization\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m                 \u001b[0mfidelity_dict\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0;31m# for key in fidelity_dict:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'dict' and 'float'"
     ]
    }
   ],
   "source": [
    "################ Benchmark Loop\n",
    "\n",
    "# Max qubits must be 12 since the referenced files only go to 12 qubits\n",
    "MAX_QUBITS = 12\n",
    "\n",
    "# Execute program with default parameters\n",
    "def run(min_qubits=4, max_qubits=8, skip_qubits=1,max_circuits=3, num_shots=4092, method=2):\n",
    "\n",
    "    #print(f\"{benchmark_name} ({method}) Benchmark Program - Qiskit\") \n",
    "\n",
    "    max_qubits = max(max_qubits, min_qubits)        # max must be >= min\n",
    "\n",
    "    # validate parameters (smallest circuit is 4 qubits and largest is 10 qubitts)\n",
    "    max_qubits = min(max_qubits, MAX_QUBITS)\n",
    "    min_qubits = min(max(4, min_qubits), max_qubits)\n",
    "    if min_qubits % 2 == 1: min_qubits += 1  # min_qubits must be even\n",
    "    skip_qubits = max(1, skip_qubits)\n",
    "    \n",
    "    if method == 2: max_circuits = 1\n",
    "\n",
    "    if max_qubits < 4:\n",
    "        print(f\"Max number of qubits {max_qubits} is too low to run method {method} of VQE algorithm\")\n",
    "        return\n",
    "\n",
    "    global max_ckts\n",
    "    max_ckts = max_circuits\n",
    "\n",
    "    creation_times = []\n",
    "    elapsed_times = []\n",
    "    quantum_times = []\n",
    "    circuit_depths = []\n",
    "    transpiled_depths = []\n",
    "    fidelity_data = {}\n",
    "    Hf_fidelity_data = {}\n",
    "\n",
    "    global min_qbits,max_qbits,skp_qubits\n",
    "\n",
    "    min_qbits = min_qubits\n",
    "    max_qbits = max_qubits\n",
    "    skp_qubits = skip_qubits\n",
    "\n",
    "    ##########\n",
    "    \n",
    "    # Execute Benchmark Program N times for multiple circuit sizes\n",
    "    # Accumulate metrics asynchronously as circuits complete\n",
    "    for input_size in range(min_qubits, max_qubits + 1, 2):\n",
    "        num_qubits = input_size \n",
    "        # reset random seed\n",
    "        np.random.seed(0)\n",
    "\n",
    "        fidelity_data[num_qubits] = []\n",
    "        Hf_fidelity_data[num_qubits] = []\n",
    "\n",
    "        # determine the number of circuits to execute for this group\n",
    "        num_circuits = min(3, max_circuits)\n",
    "\n",
    "        num_qubits = input_size\n",
    "\n",
    "        # decides number of electrons\n",
    "        na = int(num_qubits/4)\n",
    "        nb = int(num_qubits/4)\n",
    "\n",
    "        # random seed\n",
    "        np.random.seed(0)\n",
    "\n",
    "        # create the circuit for given qubit size and simulation parameters, store time metric\n",
    "        ts = time.time()\n",
    "\n",
    "        # circuit list \n",
    "        qc_list = []\n",
    "\n",
    "        # Method 1 (default)\n",
    "        if method == 1:\n",
    "            # loop over circuits\n",
    "            for circuit_id in range(num_circuits):\n",
    "\n",
    "                # construct circuit \n",
    "                qc_single = VQEEnergy(num_qubits, na, nb, circuit_id, method).reverse_bits()               \n",
    "                qc_single.name = qc_single.name + \" \" + str(circuit_id) \n",
    "\n",
    "                # add to list \n",
    "                qc_list.append(qc_single)\n",
    "        # method 2\n",
    "        elif method == 2:\n",
    "\n",
    "            # construct all circuits\n",
    "            qc_list = VQEEnergy(num_qubits, na, nb, 0, method)#.reverse_bits()\n",
    "\n",
    "        print(f\"************\\nExecuting [{len(qc_list)}] circuits with num_qubits = {num_qubits}\")\n",
    "\n",
    "        for qc in qc_list:\n",
    "\n",
    "            # get circuit id\n",
    "            if method == 1:\n",
    "                circuit_id = qc.name.split()[2]\n",
    "            else:\n",
    "                circuit_id = qc.name.split()[0]\n",
    "\n",
    "            # record creation time\n",
    "            creation_time = time.time() - ts\n",
    "            creation_times.append(creation_time)\n",
    "            print(f\"qc of {num_qubits} qubits of type {type}\")\n",
    "            print(qc)\n",
    "\n",
    "            # Calculate circuit depth\n",
    "            depth = calculate_circuit_depth(qc)\n",
    "            circuit_depths.append(depth)\n",
    "\n",
    "            # collapse the sub-circuits used in this benchmark (for qiskit)\n",
    "            qc = qc.decompose()\n",
    "\n",
    "            # Calculate transpiled circuit depth\n",
    "            transpiled_depth = calculate_transpiled_depth(qc,basis_selector)\n",
    "            transpiled_depths.append(transpiled_depth)\n",
    "            \n",
    "            #execution\n",
    "            ts = time.time()\n",
    "            job = execute(qc, backend, shots=num_shots, **options)\n",
    "            result = job.result()\n",
    "            elapsed_time = time.time() - ts\n",
    "            elapsed_times.append(elapsed_time)\n",
    "\n",
    "            # Calculate quantum processing time (excluding creation time)\n",
    "            quantum_time = result.results[0].running_time_taken\n",
    "            quantum_times.append(quantum_time)\n",
    "\n",
    "            #ensemble probability\n",
    "            prob = result.results[0].data.partial_probability\n",
    "            print(\"prob\",prob)\n",
    "            counts = prob\n",
    "\n",
    "            for key in counts.keys():\n",
    "               counts[key] = int(counts[key] * num_shots)\n",
    "            print(\"counts=\",counts)\n",
    "\n",
    "            # load pre-computed data\n",
    "            if len(qc.name.split()) == 2:\n",
    "                filename = os.path.join(f'_common/precalculated_data_{num_qubits}_qubit.json')\n",
    "                with open(filename) as f:\n",
    "                    references = json.load(f)\n",
    "            else:\n",
    "                filename = os.path.join(f'_common/precalculated_data_{num_qubits}_qubit_method2.json')\n",
    "                with open(filename) as f:\n",
    "                    references = json.load(f)\n",
    "\n",
    "            # total circuit name (pauli string + coefficient)\n",
    "            total_name = qc.name\n",
    "            print(\"total name ============\",total_name)\n",
    "        \n",
    "            # pauli string\n",
    "            pauli_string = total_name.split()[0]\n",
    "            print(\"pauli_string ===============\",pauli_string)\n",
    "        \n",
    "            # get the correct measurement\n",
    "            print(\"len(total_name) =====\",len(total_name.split()))\n",
    "            if (len(total_name.split()) == 2):\n",
    "                correct_dist = references[pauli_string]\n",
    "            else:\n",
    "                circuit_id = int(total_name.split()[2])\n",
    "                correct_dist = references[f\"Qubits - {num_qubits} - {circuit_id}\"]\n",
    "            print(\"correct_dist :\",correct_dist)\n",
    "\n",
    "            fidelity_dict = polarization_fidelity(counts, correct_dist)\n",
    "            print(\"fidelity_dict :\",fidelity_dict)\n",
    "            # # modify fidelity based on the coefficient\n",
    "            # if (len(total_name.split()) == 2):\n",
    "            #     print(\"abs(float(total_name.split()[1])) / normalization ==========\",abs(float(total_name.split()[1])) / normalization)\n",
    "            #     fidelity_dict *= ( abs(float(total_name.split()[1])) / normalization )\n",
    "\n",
    "            # for key in fidelity_dict:\n",
    "            #     fidelity_dict[key] *= abs(float(total_name.split()[1])) / normalization\n",
    "\n",
    "\n",
    "            print(\"fidelity_dict =\",fidelity_dict)\n",
    "            \n",
    "            fidelity_data[num_qubits].append(fidelity_dict['fidelity'])\n",
    "            Hf_fidelity_data[num_qubits].append(fidelity_dict['hf_fidelity'])\n",
    "    ##########\n",
    "    \n",
    "    # print a sample circuit\n",
    "    print(\"Sample Circuit:\"); print(QC_ if QC_ != None else \"  ... too large!\")\n",
    "    print(\"\\nHartree Fock Generator 'Hf' =\"); print(Hf_ if Hf_ != None else \" ... too large!\")\n",
    "    print(\"\\nCluster Operator Example 'Cluster Op' =\"); print(CO_ if CO_ != None else \" ... too large!\")\n",
    "\n",
    "    return creation_times, elapsed_times, quantum_times, circuit_depths, transpiled_depths, fidelity_data, Hf_fidelity_data\n",
    "\n",
    "# Execute the benchmark program, accumulate metrics, and calculate circuit depths\n",
    "creation_times, elapsed_times, quantum_times, circuit_depths,transpiled_depths, fidelity_data, Hf_fidelity_data = run()\n",
    "\n",
    "\n",
    "# Define the range of qubits for the x-axis\n",
    "num_qubits_range = range(min_qbits, max_qbits+1,skp_qubits+1)\n",
    "print(\"num_qubits_range =\",num_qubits_range)\n",
    "\n",
    "# Calculate average creation time, elapsed time, quantum processing time, and circuit depth for each number of qubits\n",
    "avg_creation_times = [np.mean(creation_times[i:i+max_ckts]) for i in range(0, len(creation_times), max_ckts)]\n",
    "avg_elapsed_times = [np.mean(elapsed_times[i:i+max_ckts]) for i in range(0, len(elapsed_times), max_ckts)]\n",
    "avg_quantum_times = [np.mean(quantum_times[i:i+max_ckts]) for i in range(0, len(quantum_times), max_ckts)]\n",
    "avg_circuit_depths = [np.mean(circuit_depths[i:i+max_ckts]) for i in range(0, len(circuit_depths), max_ckts)]\n",
    "avg_transpiled_depths = [np.mean(transpiled_depths[i:i+max_ckts]) for i in range(0, len(transpiled_depths), max_ckts)]\n",
    "\n",
    "print(f\"avg_creation_times={avg_creation_times}\")\n",
    "# Plot histograms for average creation time, average elapsed time, average quantum processing time, and average circuit depth versus the number of qubits\n",
    "plt.figure(figsize=(18, 15))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.xticks(range(min(num_qubits_range), max(num_qubits_range)+1, skp_qubits))\n",
    "plt.bar(num_qubits_range, avg_creation_times, color='blue')\n",
    "plt.xlabel('Number of Qubits')\n",
    "plt.ylabel('Average Creation Time (s)')\n",
    "plt.title('Average Creation Time vs Number of Qubits')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.xticks(range(min(num_qubits_range), max(num_qubits_range)+1, skp_qubits))\n",
    "plt.bar(num_qubits_range, avg_elapsed_times, color='green',label ='Elapsed Time')\n",
    "plt.bar(num_qubits_range, avg_quantum_times, color='orange',label ='Quantum Time', width=0.2)\n",
    "plt.xlabel('Number of Qubits')\n",
    "plt.ylabel('Average Time (s)')\n",
    "plt.title('Average Time vs Number of Qubits')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.xticks(range(min(num_qubits_range), max(num_qubits_range)+1, skp_qubits))\n",
    "plt.bar(num_qubits_range, avg_transpiled_depths, color='cyan', label='Normalized Depth', width=0.4)  # Adjust width here\n",
    "plt.bar(num_qubits_range, avg_circuit_depths, color='blue', label='Algorithmic Depth', width=0.2)  # Adjust width here\n",
    "plt.xlabel('Number of Qubits')\n",
    "plt.ylabel('Average Circuit Depth')\n",
    "plt.title('Average Circuit Depth vs Number of Qubits')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate the fidelity data\n",
    "avg_f = plot_data(fidelity_data, Hf_fidelity_data, \"Fidelity Comparison\")\n",
    "\n",
    "Suptitle = f\"Volumetric Positioning - {backend}\"\n",
    "appname=backend\n",
    "QV=0\n",
    "depth_base =2\n",
    "\n",
    "ax = plot_volumetric_background(max_qubits=max_qbits, QV=QV,depth_base=depth_base, suptitle=Suptitle, colorbar_label=\"Avg Result Fidelity\")\n",
    "\n",
    "w_data = num_qubits_range\n",
    "# determine width for circuit\n",
    "w_max = 0\n",
    "for i in range(len(w_data)):\n",
    "    y = float(w_data[i])\n",
    "    w_max = max(w_max, y)\n",
    "\n",
    "d_tr_data = avg_transpiled_depths\n",
    "f_data = avg_f\n",
    "\n",
    "plot_volumetric_data(ax, w_data, d_tr_data, f_data, depth_base, fill=True,label=appname, labelpos=(0.4, 0.6), labelrot=15, type=1, w_max=w_max)\n",
    "anno_volumetric_data(ax, depth_base,label=appname, labelpos=(0.4, 0.6), labelrot=15, type=1, fill=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dc2f30-45c1-40a5-9bf9-644d63054651",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2a4f3c-a9b9-414d-948c-b2cb1950f69a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
